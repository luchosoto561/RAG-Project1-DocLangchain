{
  "provenance": {
    "url_final": "https://python.langchain.com/docs/how_to/output_parser_string/",
    "title": "How to parse text from message objects | ðŸ¦œï¸ðŸ”— LangChain",
    "fetched_at": "2025-10-06T21:56:03.420843"
  },
  "sections": [
    {
      "level": 1,
      "heading_text": "How to parse text from message objects | ðŸ¦œï¸ðŸ”— LangChain",
      "blocks": [
        {
          "type": "paragraph",
          "text": "This guide assumes familiarity with the following concepts:"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "Chat models",
            "Messages",
            "Output parsers",
            "LangChain Expression Language (LCEL)"
          ]
        },
        {
          "type": "paragraph",
          "text": "LangChain message objects support content in a variety of formats, including text, multimodal data, and a list of content block dicts."
        },
        {
          "type": "paragraph",
          "text": "The format of Chat model response content may depend on the provider. For example, the chat model for Anthropic will return string content for typical string input:"
        },
        {
          "type": "code",
          "code": "from langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")response = llm.invoke(\"Hello\")response.content"
        },
        {
          "type": "code",
          "code": "'Hi there! How are you doing today? Is there anything I can help you with?'"
        },
        {
          "type": "paragraph",
          "text": "But when tool calls are generated, the response content is structured into content blocks that convey the model's reasoning process:"
        },
        {
          "type": "code",
          "code": "from langchain_core.tools import tool@tooldef get_weather(location: str) -> str:    \"\"\"Get the weather from a location.\"\"\"    return \"Sunny.\"llm_with_tools = llm.bind_tools([get_weather])response = llm_with_tools.invoke(\"What's the weather in San Francisco, CA?\")response.content"
        },
        {
          "type": "code",
          "code": "[{'text': \"I'll help you get the current weather for San Francisco, California. Let me check that for you right away.\",  'type': 'text'}, {'id': 'toolu_015PwwcKxWYctKfY3pruHFyy',  'input': {'location': 'San Francisco, CA'},  'name': 'get_weather',  'type': 'tool_use'}]"
        },
        {
          "type": "paragraph",
          "text": "To automatically parse text from message objects irrespective of the format of the underlying content, we can use StrOutputParser. We can compose it with a chat model as follows:"
        },
        {
          "type": "code",
          "code": "from langchain_core.output_parsers import StrOutputParserchain = llm_with_tools | StrOutputParser()"
        },
        {
          "type": "paragraph",
          "text": "StrOutputParser simplifies the extraction of text from message objects:"
        },
        {
          "type": "code",
          "code": "response = chain.invoke(\"What's the weather in San Francisco, CA?\")print(response)"
        },
        {
          "type": "code",
          "code": "I'll help you check the weather in San Francisco, CA right away."
        },
        {
          "type": "paragraph",
          "text": "This is particularly useful in streaming contexts:"
        },
        {
          "type": "code",
          "code": "for chunk in chain.stream(\"What's the weather in San Francisco, CA?\"):    print(chunk, end=\"|\")"
        },
        {
          "type": "code",
          "code": "|I'll| help| you get| the current| weather for| San Francisco, California|. Let| me retrieve| that| information for you.||||||||||"
        },
        {
          "type": "paragraph",
          "text": "See the API Reference for more information."
        }
      ],
      "children": []
    }
  ]
}