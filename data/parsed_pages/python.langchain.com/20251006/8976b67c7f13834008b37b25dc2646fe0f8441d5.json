{
  "provenance": {
    "url_final": "https://python.langchain.com/docs/how_to/response_metadata/",
    "title": "Response metadata | ü¶úÔ∏èüîó LangChain",
    "fetched_at": "2025-10-06T21:56:16.051556"
  },
  "sections": [
    {
      "level": 1,
      "heading_text": "Response metadata | ü¶úÔ∏èüîó LangChain",
      "blocks": [
        {
          "type": "paragraph",
          "text": "Many model providers include some metadata in their chat generation responses. This metadata can be accessed via the AIMessage.response_metadata: Dict attribute. Depending on the model provider and model configuration, this can contain information like token counts, logprobs, and more."
        },
        {
          "type": "paragraph",
          "text": "Here's what the response metadata looks like for a few different providers:"
        }
      ],
      "children": [
        {
          "level": 2,
          "heading_text": "OpenAI‚Äã",
          "anchor": "openai",
          "blocks": [
            {
              "type": "code",
              "code": "from langchain_openai import ChatOpenAIllm = ChatOpenAI(model=\"gpt-4o-mini\")msg = llm.invoke(\"What's the oldest known example of cuneiform\")msg.response_metadata"
            },
            {
              "type": "code",
              "code": "{'token_usage': {'completion_tokens': 88,  'prompt_tokens': 16,  'total_tokens': 104,  'completion_tokens_details': {'accepted_prediction_tokens': 0,   'audio_tokens': 0,   'reasoning_tokens': 0,   'rejected_prediction_tokens': 0},  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByN1Qkvqb5fAGKKzXXxZ3rBlnqkWs', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "Anthropic‚Äã",
          "anchor": "anthropic",
          "blocks": [
            {
              "type": "code",
              "code": "from langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\")msg = llm.invoke(\"What's the oldest known example of cuneiform\")msg.response_metadata"
            },
            {
              "type": "code",
              "code": "{'id': 'msg_01NTWnqvbNKSjGfqQL7xikau', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0,  'cache_read_input_tokens': 0,  'input_tokens': 17,  'output_tokens': 197,  'server_tool_use': None,  'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "Google Generative AI‚Äã",
          "anchor": "google-generative-ai",
          "blocks": [
            {
              "type": "code",
              "code": "from langchain_google_genai import ChatGoogleGenerativeAIllm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")msg = llm.invoke(\"What's the oldest known example of cuneiform\")msg.response_metadata"
            },
            {
              "type": "code",
              "code": "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "Bedrock (Anthropic)‚Äã",
          "anchor": "bedrock-anthropic",
          "blocks": [
            {
              "type": "code",
              "code": "from langchain_aws import ChatBedrockConversellm = ChatBedrockConverse(model=\"anthropic.claude-3-7-sonnet-20250219-v1:0\")msg = llm.invoke(\"What's the oldest known example of cuneiform\")msg.response_metadata"
            },
            {
              "type": "code",
              "code": "{'ResponseMetadata': {'RequestId': 'ea0ac2ad-3ad5-4a49-9647-274a0c73ac31',  'HTTPStatusCode': 200,  'HTTPHeaders': {'date': 'Sat, 22 Mar 2025 11:27:46 GMT',   'content-type': 'application/json',   'content-length': '1660',   'connection': 'keep-alive',   'x-amzn-requestid': 'ea0ac2ad-3ad5-4a49-9647-274a0c73ac31'},  'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [11044]}}"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "MistralAI‚Äã",
          "anchor": "mistralai",
          "blocks": [
            {
              "type": "code",
              "code": "from langchain_mistralai import ChatMistralAIllm = ChatMistralAI(model=\"mistral-small-latest\")msg = llm.invoke([(\"human\", \"What's the oldest known example of cuneiform\")])msg.response_metadata"
            },
            {
              "type": "code",
              "code": "{'token_usage': {'prompt_tokens': 13,  'total_tokens': 306,  'completion_tokens': 293}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop'}"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "Groq‚Äã",
          "anchor": "groq",
          "blocks": [
            {
              "type": "code",
              "code": "from langchain_groq import ChatGroqllm = ChatGroq(model=\"llama-3.1-8b-instant\")msg = llm.invoke(\"What's the oldest known example of cuneiform\")msg.response_metadata"
            },
            {
              "type": "code",
              "code": "{'token_usage': {'completion_tokens': 184,  'prompt_tokens': 45,  'total_tokens': 229,  'completion_time': 0.245333333,  'prompt_time': 0.002262803,  'queue_time': 0.19315161,  'total_time': 0.247596136}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a56f6eea01', 'finish_reason': 'stop', 'logprobs': None}"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "FireworksAI‚Äã",
          "anchor": "fireworksai",
          "blocks": [
            {
              "type": "code",
              "code": "from langchain_fireworks import ChatFireworksllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")msg = llm.invoke(\"What's the oldest known example of cuneiform\")msg.response_metadata"
            },
            {
              "type": "code",
              "code": "{'token_usage': {'prompt_tokens': 25,  'total_tokens': 352,  'completion_tokens': 327}, 'model_name': 'accounts/fireworks/models/llama-v3p1-70b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}"
            },
            {
              "type": "list",
              "ordered": false,
              "items": [
                "OpenAI",
                "Anthropic",
                "Google Generative AI",
                "Bedrock (Anthropic)",
                "MistralAI",
                "Groq",
                "FireworksAI"
              ]
            }
          ],
          "children": []
        }
      ]
    }
  ]
}