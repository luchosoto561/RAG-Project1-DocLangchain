{
  "provenance": {
    "url_final": "https://python.langchain.com/docs/how_to/callbacks_constructor/",
    "title": "How to propagate callbacks  constructor | 🦜️🔗 LangChain",
    "fetched_at": "2025-10-06T21:54:59.935560"
  },
  "sections": [
    {
      "level": 1,
      "heading_text": "How to propagate callbacks  constructor | 🦜️🔗 LangChain",
      "blocks": [
        {
          "type": "paragraph",
          "text": "This guide assumes familiarity with the following concepts:"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "Callbacks",
            "Custom callback handlers"
          ]
        },
        {
          "type": "paragraph",
          "text": "Most LangChain modules allow you to pass callbacks directly into the constructor (i.e., initializer). In this case, the callbacks will only be called for that instance (and any nested runs)."
        },
        {
          "type": "paragraph",
          "text": "Constructor callbacks are scoped only to the object they are defined on. They are not inherited by children of the object. This can lead to confusing behavior, and it's generally better to pass callbacks as a run time argument."
        },
        {
          "type": "paragraph",
          "text": "Here's an example:"
        },
        {
          "type": "code",
          "code": "from typing import Any, Dict, Listfrom langchain_anthropic import ChatAnthropicfrom langchain_core.callbacks import BaseCallbackHandlerfrom langchain_core.messages import BaseMessagefrom langchain_core.outputs import LLMResultfrom langchain_core.prompts import ChatPromptTemplateclass LoggingHandler(BaseCallbackHandler):    def on_chat_model_start(        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs    ) -> None:        print(\"Chat model started\")    def on_llm_end(self, response: LLMResult, **kwargs) -> None:        print(f\"Chat model ended, response: {response}\")    def on_chain_start(        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs    ) -> None:        print(f\"Chain {serialized.get('name')} started\")    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:        print(f\"Chain ended, outputs: {outputs}\")callbacks = [LoggingHandler()]llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", callbacks=callbacks)prompt = ChatPromptTemplate.from_template(\"What is 1 + {number}?\")chain = prompt | llmchain.invoke({\"number\": \"2\"})"
        },
        {
          "type": "code",
          "code": "Chat model startedChat model ended, response: generations=[[ChatGeneration(text='1 + 2 = 3', message=AIMessage(content='1 + 2 = 3', additional_kwargs={}, response_metadata={'id': 'msg_01DQMbSk263KpY2vouHM5gsC', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 16, 'output_tokens': 13, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--ab896e4e-c3fd-48b1-a41a-b6b525cbc041-0', usage_metadata={'input_tokens': 16, 'output_tokens': 13, 'total_tokens': 29, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}))]] llm_output={'id': 'msg_01DQMbSk263KpY2vouHM5gsC', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 16, 'output_tokens': 13, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'} run=None type='LLMResult'"
        },
        {
          "type": "code",
          "code": "AIMessage(content='1 + 2 = 3', additional_kwargs={}, response_metadata={'id': 'msg_01DQMbSk263KpY2vouHM5gsC', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 16, 'output_tokens': 13, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--ab896e4e-c3fd-48b1-a41a-b6b525cbc041-0', usage_metadata={'input_tokens': 16, 'output_tokens': 13, 'total_tokens': 29, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
        },
        {
          "type": "paragraph",
          "text": "You can see that we only see events from the chat model run - no chain events from the prompt or broader chain."
        }
      ],
      "children": [
        {
          "level": 2,
          "heading_text": "Next steps​",
          "anchor": "next-steps",
          "blocks": [
            {
              "type": "paragraph",
              "text": "You've now learned how to pass callbacks into a constructor."
            },
            {
              "type": "paragraph",
              "text": "Next, check out the other how-to guides in this section, such as how to pass callbacks at runtime."
            },
            {
              "type": "list",
              "ordered": false,
              "items": [
                "Next steps"
              ]
            }
          ],
          "children": []
        }
      ]
    }
  ]
}