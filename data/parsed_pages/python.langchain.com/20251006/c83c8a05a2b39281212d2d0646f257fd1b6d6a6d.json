{
  "provenance": {
    "url_final": "https://python.langchain.com/docs/how_to/inspect/",
    "title": "How to inspect runnables | ü¶úÔ∏èüîó LangChain",
    "fetched_at": "2025-10-06T21:55:44.837537"
  },
  "sections": [
    {
      "level": 1,
      "heading_text": "How to inspect runnables | ü¶úÔ∏èüîó LangChain",
      "blocks": [
        {
          "type": "paragraph",
          "text": "This guide assumes familiarity with the following concepts:"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "LangChain Expression Language (LCEL)",
            "Chaining runnables"
          ]
        },
        {
          "type": "paragraph",
          "text": "Once you create a runnable with LangChain Expression Language, you may often want to inspect it to get a better sense for what is going on. This notebook covers some methods for doing so."
        },
        {
          "type": "paragraph",
          "text": "This guide shows some ways you can programmatically introspect the internal steps of chains. If you are instead interested in debugging issues in your chain, see this section instead."
        },
        {
          "type": "paragraph",
          "text": "First, let's create an example chain. We will create one that does retrieval:"
        },
        {
          "type": "code",
          "code": "%pip install -qU langchain langchain-openai faiss-cpu tiktoken"
        },
        {
          "type": "code",
          "code": "from langchain_community.vectorstores import FAISSfrom langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.runnables import RunnablePassthroughfrom langchain_openai import ChatOpenAI, OpenAIEmbeddingsvectorstore = FAISS.from_texts(    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings())retriever = vectorstore.as_retriever()template = \"\"\"Answer the question based only on the following context:{context}Question: {question}\"\"\"prompt = ChatPromptTemplate.from_template(template)model = ChatOpenAI()chain = (    {\"context\": retriever, \"question\": RunnablePassthrough()}    | prompt    | model    | StrOutputParser())"
        }
      ],
      "children": [
        {
          "level": 2,
          "heading_text": "Get a graph‚Äã",
          "anchor": "get-a-graph",
          "blocks": [
            {
              "type": "paragraph",
              "text": "You can use the get_graph() method to get a graph representation of the runnable:"
            },
            {
              "type": "code",
              "code": "chain.get_graph()"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "Print a graph‚Äã",
          "anchor": "print-a-graph",
          "blocks": [
            {
              "type": "paragraph",
              "text": "While that is not super legible, you can use the print_ascii() method to show that graph in a way that's easier to understand:"
            },
            {
              "type": "code",
              "code": "chain.get_graph().print_ascii()"
            },
            {
              "type": "code",
              "code": "           +---------------------------------+                    | Parallel<context,question>Input |                    +---------------------------------+                             **               **                                 ***                   ***                            **                         **           +----------------------+              +-------------+  | VectorStoreRetriever |              | Passthrough |  +----------------------+              +-------------+                      **               **                                      ***         ***                                           **     **                                +----------------------------------+                   | Parallel<context,question>Output |                   +----------------------------------+                                     *                                                      *                                                      *                                           +--------------------+                                 | ChatPromptTemplate |                                 +--------------------+                                            *                                                      *                                                      *                                               +------------+                                         | ChatOpenAI |                                         +------------+                                                *                                                      *                                                      *                                            +-----------------+                                    | StrOutputParser |                                    +-----------------+                                              *                                                      *                                                      *                                         +-----------------------+                              | StrOutputParserOutput |                              +-----------------------+"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "Get the prompts‚Äã",
          "anchor": "get-the-prompts",
          "blocks": [
            {
              "type": "paragraph",
              "text": "You may want to see just the prompts that are used in a chain with the get_prompts() method:"
            },
            {
              "type": "code",
              "code": "chain.get_prompts()"
            },
            {
              "type": "code",
              "code": "[ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'))])]"
            }
          ],
          "children": []
        },
        {
          "level": 2,
          "heading_text": "Next steps‚Äã",
          "anchor": "next-steps",
          "blocks": [
            {
              "type": "paragraph",
              "text": "You've now learned how to introspect your composed LCEL chains."
            },
            {
              "type": "paragraph",
              "text": "Next, check out the other how-to guides on runnables in this section, or the related how-to guide on debugging your chains."
            },
            {
              "type": "list",
              "ordered": false,
              "items": [
                "Get a graph",
                "Print a graph",
                "Get the prompts",
                "Next steps"
              ]
            }
          ],
          "children": []
        }
      ]
    }
  ]
}